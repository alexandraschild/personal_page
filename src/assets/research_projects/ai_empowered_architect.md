## Overview

Designing architectural structures that are both physically feasible and emotionally engaging is a complex challenge. Architects often invest significant effort trying to capture a desired “vibe” or aesthetic, yet have limited means to assess structural efficiency or feasibility in the early design stages. At the same time, traditional architectural tools primarily focus on geometry, stability, and energy performance, while the emotional or aesthetic response of a structure remains intangible and difficult to quantify. 

Our research investigates how multimodal AI models, such as vision–language models (VLMs), can assist architects in generating **physically grounded structures that evoke specific feelings**, bridging creativity, affective response, structural feasibility and efficiency.

## Research Motivation

Architectural design involves multiple intertwined objectives: functionality, structural performance, and aesthetic or emotional impact. Capturing these objectives computationally requires models that can:

1. Reason about geometry and structure in a physically valid manner.
2. Anticipate human responses to shapes, forms, and spatial arrangements.
3. Learn representations that encode both functional and emotional dimensions.
4. Allow control over individual aspects of the design to explore trade-offs.

Collaborating with MIT Architecture Department, our goal is to **equip architects with AI-assisted tools** that suggest modifications, generate novel topologies, or optimize existing designs while maintaining both physical validity and emotional resonance.

## Core Challenges

This project encompasses several major challenges:

1. **Affectionate Computing and Reasoning** – The model must understand how a given shape or spatial configuration may influence a person's emotional response. This requires bridging geometric understanding with human affective perception.

2. **Physical Grounding** – Designs must remain physically feasible. Models should propose modifications that adhere to structural constraints while achieving closer alignment with desired inspirations or moods. Ideally, the system could generate **new valid topologies** from a design intent.

3. **Geometric Representation Learning** – Developing representations that encode both **structural performance metrics** (e.g., energy efficiency, embodied footprint) and **visual/aesthetic properties**. These representations need to be expressive enough for downstream generation and evaluation.

4. **Disentanglement for Control** – To give architects meaningful control, the representations should separate dimensions corresponding to geometry, performance, and affect, allowing targeted edits without undesired side effects.

<h2><span style="color:#4A90E2;">Collaborations / Supervision</span></h2>

If you read till here, there is a chance you are interested in similar topics or a joint project:)

I am actively interested in collaborations and joint research projects related to this project. In particular (but not limited to), I welcome opportunities to work with researchers exploring geometric deep learning, computational design and affective computing. Feel free to drop me a message if you are interested in contributing to this project or joint work on similar topics.

I am also open to **Master Thesis supervision** within this scope (I will be on research stay at MIT in spring 2026, therefore preferably starting Summer 2026). Please, attach your CV and Transcripts.
